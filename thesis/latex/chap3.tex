\chapter{Latent Factor Topic Modelling}

% \begin{figure}[h]
%    {\includegraphics[scale=1]{img/PearsonEqn.png}}
% \end{figure}
Topic Modelling has been a way to comprehend text for the machine learning community. This can be of supervised or unsupervised nature. For the task of this thesis, we have employed the unsupervised version of the topic modelling. A number of simple unsupervised methods can be used for feature selection in text clustering. Some examples of such methods are discussed below.

\section{Document Frequency-based Selection}
The simplest possible method for feature selection in document clustering is that of the use of document frequency to filter out irrelevant features. While the use of inverse document frequencies reduces the importance of such words, this may not alone be sufficient to reduce the noise effects of very frequent words. In other words, words which are too frequent in the corpus can be removed because they are typically common words such as “a”, “an”, “the”, or “of” which are not discriminative from a clustering perspective. Such words are also referred to as stop words.
A variety of methods are commonly available in the literature [76] for stop-word removal.  Typically commonly available stop word lists of
about 300 to 400 words are used for the retrieval process. In addition,
words which occur extremely infrequently can also be removed from
the collection. This is because such words do not add anything to the
similarity computations which are used in most clustering methods. In



3.2

