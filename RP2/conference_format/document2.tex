%%% Note that the a4paper option is mainly intended so that authors in
% countries using A4 can easily print to A4 and see how their papers will
% look in print - the typesetting of the document will not typically be
% affected with changes in paper size (but the bottom and side margins will).
% Use the testflow package mentioned above to verify correct handling of
% both paper sizes by the user's LaTeX system.
%
% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
\documentclass[10pt,conference]{IEEEtran}
% Add the compsoc option for Computer Society conferences.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}
%
\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




%\usepackage{array}




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/url/
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\usepackage[english]{babel}
\usepackage{graphicx, type1cm, lettrine}

\usepackage[sort&compress, numbers]{natbib}


\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
% Do not put math or special symbols in the title.
% title actual
% Collaborative filtering: Techniques and Applications
\title{Recommendations based on Matrix Facotirzation and Latent Dirichlet Allocation}

% author names and affiliations
% use a multiple column layout for up to three different
% affiliations

\author{
\IEEEauthorblockN{Rahul Bali}
\IEEEauthorblockA{Department of Computer Science\\
Punjab Engineering College\\
Chandigarh, India\\
Email: rahulrdb18@gmail.com}
% email: rahulbali.mecse16@pec.edu.in
\and
\IEEEauthorblockN{Shilpa Verma}
\IEEEauthorblockA{Department of Computer Science\\
Punjab Engineering College\\
Chandigarh, India\\
Email: shilpaverma.pec@gmail.com}}



% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 

% a kind of multiline comment
\iffalse

\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
Homer Simpson\IEEEauthorrefmark{2},
James Kirk\IEEEauthorrefmark{3}, 
Montgomery Scott\IEEEauthorrefmark{3} and
Eldon Tyrell\IEEEauthorrefmark{4}}
\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
Georgia Institute of Technology,
Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
Email: homer@thesimpsons.com}
\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
Telephone: (800) 555--1212, Fax: (888) 555--1212}
\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}

I don't want this to happen
\fi


% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}
	Although latent factor models (e.g., matrix factorization) achieve good accuracy in rating prediction, they suffer from several prob- lems including cold-start, non-transparency, and suboptimal recom- mendation for local users or items. In this paper, we employ textual review information with ratings to tackle these limitations. Firstly, we apply a proposed aspect-aware topic model (ATM) on the review text to model user preferences and item features from different as- pects, and estimate the aspect importance of a user towards an item. The aspect importance is then integrated into a novel aspect-aware latent factor model (ALFM), which learns user’s and item’s latent factors based on ratings. In particular, ALFM introduces a weighted matrix to associate those latent factors with the same set of aspects discovered by ATM, such that the latent factors could be used to estimate aspect ratings. Finally, the overall rating is computed via a linear combination of the aspect ratings, which are weighted by the corresponding aspect importance. To this end, our model could alleviate the data sparsity problem and gain good interpretability for recommendation. Besides, an aspect rating is weighted by an aspect importance, which is dependent on the targeted user’s preferences and targeted item’s features. Therefore, it is expected that the proposed method can model a user’s preferences on an item more accurately for each user-item pair locally. Comprehensive experimental studies have been conducted on three datasets from Amazon dataset. Results show that our method achieves significant improvement compared with strong baseline methods, especially for users with only few ratings. Moreover, our model could interpret the recommendation results in depth.
\end{abstract}


% no keywords
% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle


%% keywords for the writing.
%%% information overload
%%% computer-human interaction
%%% 
\section{Introduction}


Nowadays, most people use the Internet and spend more time on social networks or e-commerce
sites than in the past. The exponential growth of the amount of information on the Internet has
made users face challenges in finding useful information [1 – 3]. Fortunately, studying the users’
behaviors, their preferences can be analyzed. Recommender systems (RS) are used to do so [ 4 ].
Recommender systems adopt to provide recommendations to each user based on their activity,
preferences, and behaviors which are consistent with the users’ personal preferences and assist them
in decision-making [5].


Moreover, MF cannot achieve optimal rating prediction locally for each user-item pair, because it learns the latent factors of users ($p_u$ ) and items ($q_i$) via a global optimization strategy [10]. In other words, $p_u$ and $q_i$ are optimized to achieve a global optimization over all the user-item ratings in the training dataset.1 As a result, the performance could be severely compromised locally for individual users or items. MF predicts an unknown rating by the dot product of the targeted user $u$'s and item $i$'s latent factors. The overall rating of a user towards an item $r_{u,i}$ ) is decided by the importance/contribution of all factors. Take the k-th factor as anexample, its contribution is pu,k ∗qi,k . For accurate prediction, it is important to accurately capture the importance ofeach latent factor for a user towards an item. It is well-known that different users may care about different aspects of an item. For example, in the domain of restaurants, some users care more about the taste of food while others pay more attention to the ambience. Even for the same aspect, the preference of users could be different from each other. For example, in the food aspect, some users like Chinese cuisines while some others favor Italian cuisines. Similarly, the characteristics of items on an aspect could also be different from each other.
\cite{linden2003amazon}

Recommender systems are implemented with three techniques including: content-based [6], knowledge-based [7], and collaborative filtering [8]. Collaborative filtering (CF) is one of the most commonly used techniques in RS [9 – 11]. In this study, we use collaborative filtering. In CF, opinions and ratings of similar users to the target user are used to provide recommendations. The target user is a user who should receive recommendations. In fact, the core of CF is to find the similarities between users. CF is possible in two ways: using memory-based and model-based approaches [12]; the combination of these two methods is also used [13 , 14]. The memory-based CF is used in this study. In the memory-based method, the similarity between users is calculated using one of three techniques of similarity algorithms [10, 15], similarity measures [16 – 21], or heuristics methods [22]. Similarity measures are used this study. Then, a rating is predicted for the items that are not rated by the target user using rating prediction formulas. Finally, the items with the highest predicted ratings are recommended to the target user [10,17,23].


\section{Related Work}
When making comments on an item (e.g., product, movie, and restaurant) in the online review/business websites, such as Amazon, reviewers also provide an overall rating, which indicates their overall preference or satisfaction towards the corresponding items. Hence, predicting users' overall ratings to unrated items or personalized rating prediction is an important research problem in recommender systems. Latent factor models (e.g., matrix factorization [9, 21, 37]) are the most widely used and successful techniques for rating prediction, as demonstrated by the Netflix Prize contest [3]. These methods characterize user's interests and item's features using latent factors inferred from rating patterns in user-item rating records. As a typical collaborative filtering technique, the performance of MF suffers when the ratings of items or users are insufficient (also known as the cold-start problem) [17]. Besides, a rating only indicates the overall satisfaction of a user towards an item, it cannot explain the underlying rationale. For example, a user could give a restaurant a high rating because of its delicious food or due to its nice ambience. Most existing MF models cannot provide such fine-grained analysis. Therefore, relying solely on ratings makes these methods hard to explicitly and accurately model users' preferences [17, 23, 26, 35, 36].

\textbf{Topic-based}: 

In the recent work [16], the authors proposed the Hidden Factors and Hidden Topics (HFT) model, which learnt a Latent Dirichlet Allocation (LDA) [3] model for items using the review text and a matrix factorization model to fit the ratings. To bridge the gap between the stochastic vector obtained from LDA and the real- valued vector in MF model, the authors proposed a transforma- tion to link the two. Their method demonstrated significant im- provement over baseline methods that use ratings or reviews alone. However, the transformation function they employ, the exponential function, fixed the relationship between latent vector in MF and the topic distribution. Although a parameter is employed to maintain a more flexible relationship, it is still difficult to ensure that this transformation is correctly scaled.
These approaches extract latent topics or aspects from reviews. An early work [14] in this direction relied on domain knowledge to manually label reviews into different aspects, which requires expensive domain knowledge and high labor cost. Later on, most works attempt to extract latent topics or aspects from reviews automatically [2, 12, 17, 23, 26, 26, 31, 36, 39]. A general approach of these methods is to extract latent topics from reviews using topic models [23, 26, 31, 32, 39] or non-negative MF [2, 29] and learn latent factors from ratings using MF methods. HFT [26] and TopicMF [2] link the latent topics and latent factors by using a defined transform function. ITLFM [39] and RBLT [31] assume that the latent topics and latent factors are in the same space, and linearly combine them to form the latent representations for users and items to model the ratings in MF. CTR [32] assumes that the latent factors of items depend on the latent topic distributions of their text, and adds a latent variable to offset the topic distributions of items when modeling the ratings. RMR [23] also learns item’s features using topic models on reviews, while it models ratings using a mixture of Gaussian rather than MF methods. Diao et al. [12] propose an integrated graphical model called JMARS to jointly model aspects, ratings and sentiments for movie rating prediction. Those models all assume an one-to-one mapping between the learned latent topics from reviews and latent factors from ratings. Although we adopt the same strategy to extract latent topics and learn latent factors, our model does not have the constraint of one-to-one mapping. Besides, Zhang et al. [42] extracted aspects by decomposing the user–item rating matrix into item–aspect and user–aspect matrices. He et al. [17] extracted latent topics from reviews by modeling the user-item-aspect relation with a tripartite graph.

Let D be a collection of reviews of item set I from a specific category (e.g., restaurant) written by a set of users U, and each review comes with an overall rating ru,i to indicate the overall satisfaction of user u to item i. The primary goal is to predict the unknown ratings of items that the users have not reviewed yet. A review $d_{u,i}$ is a piece of text which describes opinions of user u on different aspects $a \in A$ towards item $i$, such as food for restaurants. In this paper, we only consider the case that all the items are from the same category, i.e., they share the same set of aspectsA.Aspects that users care for items are latent and learned from reviews by our proposed topic model, in which each aspect is represented as a distribution of the same set (e.g., K) of latent topics. Table 1 lists the key notations. Before introducing our method, we would like to first clarify the concepts of aspects, latent topics, and latent factors.

\section{Proposed Model}
Our model is a probabilistic generative model that combines a topic model seamlessly with a rating model. 

\subsection{Model and Notations}\
Suppose there are $N$ users $U = \{u_1,u_2, \dots ,u_N\}$, $M$ items
$V = \{v_1, v_2, \dots , v_M\}$, a set of observed indices $Q = \{i, j\}$, where $\{u_i, v_j\} \in U \times V$ defines the observed ratings $X = \{x_{i,j}\}$, each of which is optionally associated with a review $r_{i,j} = \{w|w \subset V\}$ of length $L_{i,j}$ , where $V$ is the set of vocabulary used in the reviewtext. Alternatively, let $U_j$ denote the indices of users who have rated item $v_j$. Let $K$ denote the number of topics.

This distribution describes the proportion that the item belongs to each topic.

\begin{enumerate}

	\bigskip 
	\item For each user $u \in U$:
		\medskip
		\begin{enumerate}
			\item For each latent topic dimension $k \in [1, K]$:
				\smallskip
				\begin{enumerate}
					\item Draw $\mu_{u,k} \sim Gaussian(\mu_0, \sigma^2_0)$
				\end{enumerate}
		\end{enumerate}
	\bigskip 
	\item For each latent topic dimension $k \in [1, K]:$
		\medskip
		\begin{enumerate}
			\item Draw $\psi_k \sim Dirichlet(\beta)$
			\smallskip
		\end{enumerate}
	\bigskip 
	\item For each item $v \in V$:
		\medskip
		\begin{enumerate}
			\item Draw topic mixture proportion $\theta_v \sim Dirichlet(\alpha)$
			\smallskip 
			\item For each description word $w{v,n}$
			\smallskip
			\begin{enumerate}
				\item Draw topic assignment $z_{v,n}$ $\sim$ $Multinomial(\theta_v)$
				\item Draw word,\\ $w_{v,n}$ $\sim$ $Multinomial(\psi_{Z_{v,n}})$
			\end{enumerate}
			\item For each observed rating assigned by $u$ to $v$:
			\begin{enumerate}
				\item Draw topic assignment,\\ $f_{v,u} \sim Multinomial(\theta_v)$
				\item Draw the rating,\\ $x_{v,u}$ $\sim$ $Gaussian(\mu_u,f_{v,u},\sigma^2)$
			\end{enumerate}

		\end{enumerate}
	\bigskip 
\end{enumerate}

\section{Experiments and Results}

\section{Conclusion}

\newpage
\bibliographystyle{IEEEtran}
\bibliography{ref}

% that's all folks
\end{document}


